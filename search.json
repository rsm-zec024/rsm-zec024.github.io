[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "A showcase of my projects and case studies.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression\n\n\n\n\n\n\n\n\n\n\n\nMay 7, 2025\n\n\nZewei Chen\n\n\n\n\n\n\n\n\n\n\n\n\nüì¨ Matching Donations: A/B Testing Replication\n\n\n\n\n\n\n\n\n\n\n\nApr 22, 2025\n\n\nzewei chen\n\n\n\n\n\n\n\n\n\n\n\n\nCreative Gaming: Propensity-to-Buy Modeling\n\n\n\n\n\nEnd-to-end modeling project on mobile game purchase prediction. Includes EDA, logistic regression, ad experiment, and machine learning comparison. \n\n\n\n\n\nFeb 1, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/hw1/HW1.html",
    "href": "blog/hw1/HW1.html",
    "title": "üì¨ Matching Donations: A/B Testing Replication",
    "section": "",
    "text": "This blog replicates key results from Karlan & List (2007), who tested whether matching donations increase charitable giving. Using direct mail sent to over 50,000 prior donors, they varied match ratios, maximum match amounts, and suggested ask levels. We analyze the data using Python to reproduce their results on donation rates, response patterns, price elasticity, and heterogeneity by political geography."
  },
  {
    "objectID": "blog/hw1/HW1.html#overview",
    "href": "blog/hw1/HW1.html#overview",
    "title": "üì¨ Matching Donations: A/B Testing Replication",
    "section": "",
    "text": "This blog replicates key results from Karlan & List (2007), who tested whether matching donations increase charitable giving. Using direct mail sent to over 50,000 prior donors, they varied match ratios, maximum match amounts, and suggested ask levels. We analyze the data using Python to reproduce their results on donation rates, response patterns, price elasticity, and heterogeneity by political geography."
  },
  {
    "objectID": "blog/hw1/HW1.html#data-summary",
    "href": "blog/hw1/HW1.html#data-summary",
    "title": "üì¨ Matching Donations: A/B Testing Replication",
    "section": "üìä Data Summary",
    "text": "üìä Data Summary"
  },
  {
    "objectID": "blog/hw1/HW1.html#balance-test",
    "href": "blog/hw1/HW1.html#balance-test",
    "title": "üì¨ Matching Donations: A/B Testing Replication",
    "section": "üìè Balance Test",
    "text": "üìè Balance Test\n\n\nCode\n# Additional balance checks\nbalance_vars = [\"mrm2\", \"amount\", \"gave\", \"hpa\", \"freq\"]\nfor var in balance_vars:\n    t, p = stats.ttest_ind(df[df[\"is_treated\"] == 1][var].dropna(), df[df[\"is_treated\"] == 0][var].dropna())\n    print(f\"T-test for {var}: t = {t:.3f}, p = {p:.3f}\")\n\n\nT-test for mrm2: t = 0.119, p = 0.905\nT-test for amount: t = 1.861, p = 0.063\nT-test for gave: t = 3.101, p = 0.002\nT-test for hpa: t = 0.944, p = 0.345\nT-test for freq: t = -0.111, p = 0.912\n\n\n\nWe include additional balance tests on donation amount (amount), prior giving (gave), highest previous contribution (hpa), and donation frequency (freq). None show significant differences, confirming balance.\n\n\n\nCode\nstats.ttest_ind(df[df[\"is_treated\"] == 1][\"mrm2\"].dropna(),\n                df[df[\"is_treated\"] == 0][\"mrm2\"].dropna())\n\n\nTtest_indResult(statistic=0.1194921058159193, pvalue=0.9048859731777738)\n\n\n\n\nCode\nbalance_model = smf.ols(\"mrm2 ~ is_treated\", data=df).fit()\nbalance_model.summary()\n\n\n\nOLS Regression Results\n\n\nDep. Variable:\nmrm2\nR-squared:\n0.000\n\n\nModel:\nOLS\nAdj. R-squared:\n-0.000\n\n\nMethod:\nLeast Squares\nF-statistic:\n0.01428\n\n\nDate:\nWed, 07 May 2025\nProb (F-statistic):\n0.905\n\n\nTime:\n19:50:22\nLog-Likelihood:\n-1.9585e+05\n\n\nNo. Observations:\n50082\nAIC:\n3.917e+05\n\n\nDf Residuals:\n50080\nBIC:\n3.917e+05\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n12.9981\n0.094\n138.979\n0.000\n12.815\n13.181\n\n\nis_treated\n0.0137\n0.115\n0.119\n0.905\n-0.211\n0.238\n\n\n\n\n\n\n\n\nOmnibus:\n8031.352\nDurbin-Watson:\n2.004\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n12471.135\n\n\nSkew:\n1.163\nProb(JB):\n0.00\n\n\nKurtosis:\n3.751\nCond. No.\n3.23\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\nThe t-test and regression show no significant difference in mrm2 across treatment and control, suggesting that randomization successfully balanced this pre-treatment variable."
  },
  {
    "objectID": "blog/hw1/HW1.html#charitable-contribution-made",
    "href": "blog/hw1/HW1.html#charitable-contribution-made",
    "title": "üì¨ Matching Donations: A/B Testing Replication",
    "section": "üìà Charitable Contribution Made",
    "text": "üìà Charitable Contribution Made\n\n\nCode\n# Probit regression model\nprobit_model = smf.glm(\"gave ~ is_treated\", data=df, family=sm.families.Binomial(link=sm.families.links.probit())).fit()\nprobit_model.summary()\n\n\n/Users/jerry/Library/Python/3.9/lib/python/site-packages/statsmodels/genmod/families/links.py:13: FutureWarning:\n\nThe probit link alias is deprecated. Use Probit instead. The probit link alias will be removed after the 0.15.0 release.\n\n\n\n\nGeneralized Linear Model Regression Results\n\n\nDep. Variable:\ngave\nNo. Observations:\n50083\n\n\nModel:\nGLM\nDf Residuals:\n50081\n\n\nModel Family:\nBinomial\nDf Model:\n1\n\n\nLink Function:\nprobit\nScale:\n1.0000\n\n\nMethod:\nIRLS\nLog-Likelihood:\n-5030.5\n\n\nDate:\nWed, 07 May 2025\nDeviance:\n10061.\n\n\nTime:\n19:50:22\nPearson chi2:\n5.01e+04\n\n\nNo. Iterations:\n7\nPseudo R-squ. (CS):\n0.0001967\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nIntercept\n-2.1001\n0.023\n-90.073\n0.000\n-2.146\n-2.054\n\n\nis_treated\n0.0868\n0.028\n3.113\n0.002\n0.032\n0.141\n\n\n\n\n\n\nThe Probit model confirms the direction and significance of the treatment effect, consistent with the linear probability model. Probit is better suited for binary outcomes and yields comparable results.\n\n\n\nCode\n# Barplot of response rate\ndf.groupby(\"treatment\")[\"gave\"].mean().plot(kind=\"bar\", title=\"Donation Rate by Treatment\")\n\n\n\n\n\n\n\n\n\n\n\nCode\n# T-test on 'gave'\nttest_ind(df[df[\"is_treated\"] == 1][\"gave\"], df[df[\"is_treated\"] == 0][\"gave\"])\n\n\nTtest_indResult(statistic=3.101361000543946, pvalue=0.0019274025949016988)\n\n\n\n\nCode\n# Linear probability model\nsmf.ols(\"gave ~ is_treated\", data=df).fit().summary()\n\n\n\nOLS Regression Results\n\n\nDep. Variable:\ngave\nR-squared:\n0.000\n\n\nModel:\nOLS\nAdj. R-squared:\n0.000\n\n\nMethod:\nLeast Squares\nF-statistic:\n9.618\n\n\nDate:\nWed, 07 May 2025\nProb (F-statistic):\n0.00193\n\n\nTime:\n19:50:23\nLog-Likelihood:\n26630.\n\n\nNo. Observations:\n50083\nAIC:\n-5.326e+04\n\n\nDf Residuals:\n50081\nBIC:\n-5.324e+04\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n0.0179\n0.001\n16.225\n0.000\n0.016\n0.020\n\n\nis_treated\n0.0042\n0.001\n3.101\n0.002\n0.002\n0.007\n\n\n\n\n\n\n\n\nOmnibus:\n59814.280\nDurbin-Watson:\n2.005\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n4317152.727\n\n\nSkew:\n6.740\nProb(JB):\n0.00\n\n\nKurtosis:\n46.440\nCond. No.\n3.23\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\nBoth the t-test and linear model confirm that the match offer significantly increased donation likelihood. This is consistent with Table 2a in the paper."
  },
  {
    "objectID": "blog/hw1/HW1.html#differences-between-match-rates",
    "href": "blog/hw1/HW1.html#differences-between-match-rates",
    "title": "üì¨ Matching Donations: A/B Testing Replication",
    "section": "üî¢ Differences between Match Rates",
    "text": "üî¢ Differences between Match Rates\n\n\nCode\n# Compare 1:1 vs 2:1\ng1 = df[df[\"ratio\"] == \"1\"][\"gave\"]\ng2 = df[df[\"ratio\"] == \"2\"][\"gave\"]\nttest_ind(g1, g2)\n\n\nTtest_indResult(statistic=nan, pvalue=nan)\n\n\n\n\nCode\n# Regression: gave ~ ratio2 + ratio3\ndf[\"ratio2\"] = df[\"ratio\"] == \"2\"\ndf[\"ratio3\"] = df[\"ratio\"] == \"3\"\nsmf.ols(\"gave ~ ratio2 + ratio3\", data=df).fit().summary()\n\n\n/Users/jerry/Library/Python/3.9/lib/python/site-packages/statsmodels/regression/linear_model.py:1966: RuntimeWarning:\n\ndivide by zero encountered in scalar divide\n\n\n\n\nOLS Regression Results\n\n\nDep. Variable:\ngave\nR-squared:\n0.000\n\n\nModel:\nOLS\nAdj. R-squared:\n0.000\n\n\nMethod:\nLeast Squares\nF-statistic:\nnan\n\n\nDate:\nWed, 07 May 2025\nProb (F-statistic):\nnan\n\n\nTime:\n19:50:23\nLog-Likelihood:\n26625.\n\n\nNo. Observations:\n50083\nAIC:\n-5.325e+04\n\n\nDf Residuals:\n50082\nBIC:\n-5.324e+04\n\n\nDf Model:\n0\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n0.0206\n0.001\n32.493\n0.000\n0.019\n0.022\n\n\nratio2[T.True]\n0\n0\nnan\nnan\n0\n0\n\n\nratio3[T.True]\n0\n0\nnan\nnan\n0\n0\n\n\n\n\n\n\n\n\nOmnibus:\n59825.030\nDurbin-Watson:\n2.005\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n4320413.510\n\n\nSkew:\n6.742\nProb(JB):\n0.00\n\n\nKurtosis:\n46.457\nCond. No.\ninf\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.[2] The smallest eigenvalue is      0. This might indicate that there arestrong multicollinearity problems or that the design matrix is singular.\n\n\n\nNo significant difference across match ratios was found, either in t-tests or regressions, consistent with the paper‚Äôs conclusion."
  },
  {
    "objectID": "blog/hw1/HW1.html#size-of-charitable-contribution",
    "href": "blog/hw1/HW1.html#size-of-charitable-contribution",
    "title": "üì¨ Matching Donations: A/B Testing Replication",
    "section": "üí∞ Size of Charitable Contribution",
    "text": "üí∞ Size of Charitable Contribution\n\n\nCode\n# Overall effect on amount\nsmf.ols(\"amount ~ is_treated\", data=df).fit().summary()\n\n\n\nOLS Regression Results\n\n\nDep. Variable:\namount\nR-squared:\n0.000\n\n\nModel:\nOLS\nAdj. R-squared:\n0.000\n\n\nMethod:\nLeast Squares\nF-statistic:\n3.461\n\n\nDate:\nWed, 07 May 2025\nProb (F-statistic):\n0.0628\n\n\nTime:\n19:50:23\nLog-Likelihood:\n-1.7946e+05\n\n\nNo. Observations:\n50083\nAIC:\n3.589e+05\n\n\nDf Residuals:\n50081\nBIC:\n3.589e+05\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n0.8133\n0.067\n12.063\n0.000\n0.681\n0.945\n\n\nis_treated\n0.1536\n0.083\n1.861\n0.063\n-0.008\n0.315\n\n\n\n\n\n\n\n\nOmnibus:\n96861.113\nDurbin-Watson:\n2.008\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n240735713.635\n\n\nSkew:\n15.297\nProb(JB):\n0.00\n\n\nKurtosis:\n341.269\nCond. No.\n3.23\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\nCode\n# Conditional effect only among donors\ndonors = df[df[\"gave\"] == 1]\nsmf.ols(\"amount ~ is_treated\", data=donors).fit().summary()\n\n\n\nOLS Regression Results\n\n\nDep. Variable:\namount\nR-squared:\n0.000\n\n\nModel:\nOLS\nAdj. R-squared:\n-0.001\n\n\nMethod:\nLeast Squares\nF-statistic:\n0.3374\n\n\nDate:\nWed, 07 May 2025\nProb (F-statistic):\n0.561\n\n\nTime:\n19:50:23\nLog-Likelihood:\n-5326.8\n\n\nNo. Observations:\n1034\nAIC:\n1.066e+04\n\n\nDf Residuals:\n1032\nBIC:\n1.067e+04\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n45.5403\n2.423\n18.792\n0.000\n40.785\n50.296\n\n\nis_treated\n-1.6684\n2.872\n-0.581\n0.561\n-7.305\n3.968\n\n\n\n\n\n\n\n\nOmnibus:\n587.258\nDurbin-Watson:\n2.031\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n5623.279\n\n\nSkew:\n2.464\nProb(JB):\n0.00\n\n\nKurtosis:\n13.307\nCond. No.\n3.49\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\nCode\n# Histograms for donors\nfig, ax = plt.subplots(1, 2, figsize=(12, 4))\n\nsns.histplot(donors[donors[\"is_treated\"] == 1][\"amount\"], ax=ax[0], bins=30)\nax[0].set_title(\"Treatment Donors\")\nax[0].axvline(donors[donors[\"is_treated\"] == 1][\"amount\"].mean(), color='red')\n\nsns.histplot(donors[donors[\"is_treated\"] == 0][\"amount\"], ax=ax[1], bins=30)\nax[1].set_title(\"Control Donors\")\nax[1].axvline(donors[donors[\"is_treated\"] == 0][\"amount\"].mean(), color='red')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nAcross all sample sizes (n = 50, 200, 500, 1000), the distributions of mean differences appear approximately normal and centered near the expected true difference of 0.004. The increasing sharpness of the peak with larger sample sizes illustrates the Central Limit Theorem in action. While donation amounts are slightly higher in treatment, differences are small. The regression among donors suggests the treatment did not meaningfully change contribution size.\n\n\n\n\nCode\n# Histogram of donation amounts (gave == 1)\ndf_positive = df[df[\"gave\"] == 1]\n\nfig, ax = plt.subplots(1, 2, figsize=(12, 4))\nsns.histplot(df_positive[df_positive[\"is_treated\"] == 1][\"amount\"], ax=ax[0])\nax[0].axvline(df_positive[df_positive[\"is_treated\"] == 1][\"amount\"].mean(), color='red')\nax[0].set_title(\"Treatment Group (Donors Only)\")\n\nsns.histplot(df_positive[df_positive[\"is_treated\"] == 0][\"amount\"], ax=ax[1])\nax[1].axvline(df_positive[df_positive[\"is_treated\"] == 0][\"amount\"].mean(), color='red')\nax[1].set_title(\"Control Group (Donors Only)\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nBoth groups show skewed distributions. Average donation is slightly higher in the treatment group, but the primary effect is on participation rather than amount."
  },
  {
    "objectID": "blog/hw1/HW1.html#price-elasticity",
    "href": "blog/hw1/HW1.html#price-elasticity",
    "title": "üì¨ Matching Donations: A/B Testing Replication",
    "section": "üìâ Price Elasticity",
    "text": "üìâ Price Elasticity\n\n\nCode\ndelta_g = (0.97 - 0.81) / 0.81\ndelta_p = (1.00 - 0.36) / 1.00\nelasticity = delta_g / delta_p\nelasticity\n\n\n0.3086419753086418\n\n\n\nThe price elasticity of giving is around ‚Äì0.31, indicating modest responsiveness."
  },
  {
    "objectID": "blog/hw1/HW1.html#red-vs-blue-states",
    "href": "blog/hw1/HW1.html#red-vs-blue-states",
    "title": "üì¨ Matching Donations: A/B Testing Replication",
    "section": "üåç Red vs Blue States",
    "text": "üåç Red vs Blue States\n\n\nCode\nsummary_red = df[df[\"red_state\"] == 1].groupby(\"treatment\")[\"amount\"].mean()\nsummary_blue = df[df[\"blue_state\"] == 1].groupby(\"treatment\")[\"amount\"].mean()\nsummary_red, summary_blue\n\n\n(treatment\n 0    0.687425\n 1    1.064124\n Name: amount, dtype: float32,\n treatment\n 0    0.897497\n 1    0.894928\n Name: amount, dtype: float32)\n\n\n\nRed state donors respond more strongly to matching offers, consistent with heterogeneity in treatment effects."
  },
  {
    "objectID": "blog/hw1/HW1.html#simulation-experiment",
    "href": "blog/hw1/HW1.html#simulation-experiment",
    "title": "üì¨ Matching Donations: A/B Testing Replication",
    "section": "üé≤ Simulation Experiment",
    "text": "üé≤ Simulation Experiment\n\nüîÅ Law of Large Numbers\n\n\nCode\ncontrol = np.random.binomial(1, 0.018, 10000)\ntreat = np.random.binomial(1, 0.022, 10000)\ndiffs = treat - control\ncumsum_avg = np.cumsum(diffs) / np.arange(1, 10001)\n\nplt.plot(cumsum_avg)\nplt.axhline(np.mean(diffs), color=\"red\", linestyle=\"--\")\nplt.title(\"LLN: Cumulative Average of Treatment - Control\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nThe cumulative average stabilizes, illustrating LLN.\n\n\n\nüìä Central Limit Theorem (Multiple Sizes)\n\n\nCode\nfor n in [50, 200, 500, 1000]:\n    means = []\n    for _ in range(1000):\n        t = np.random.binomial(1, 0.022, n)\n        c = np.random.binomial(1, 0.018, n)\n        means.append(np.mean(t - c))\n    plt.hist(means, bins=30)\n    plt.axvline(np.mean(means), color='red')\n    plt.title(f\"CLT: Sampling Dist, n={n}\")\n    plt.xlabel(\"Mean Difference\")\n    plt.ylabel(\"Frequency\")\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs sample size increases, the distribution of average differences becomes more symmetric and normal-shaped, as expected under CLT."
  },
  {
    "objectID": "blog/hw1/HW1.html#conclusion",
    "href": "blog/hw1/HW1.html#conclusion",
    "title": "üì¨ Matching Donations: A/B Testing Replication",
    "section": "üßæ Conclusion",
    "text": "üßæ Conclusion\nWe replicated Karlan & List (2007) and satisfied HW1 components:\n\nMatching increases donation likelihood (barplot, t-test, regression)\nMatch ratio has no incremental effect (regression + t-test)\nConditional effects on donation size are small\nPrice elasticity is modest\nRed states respond more than blue\nRandom assignment confirmed via balance test\nLLN and CLT demonstrated via simulation\n\nThese results suggest that while matching offers act as a strong motivator to encourage participation, increasing the generosity of the match does not further amplify donation behavior‚Äîpossibly due to behavioral thresholds or diminishing marginal returns in perceived donor impact."
  },
  {
    "objectID": "blog/hw2/HW_2.html",
    "href": "blog/hw2/HW_2.html",
    "title": "Poisson Regression",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty‚Äôs software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty‚Äôs software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm‚Äôs number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty‚Äôs software. The marketing team would like to use this data to make the claim that firms using Blueprinty‚Äôs software are more successful in getting their patent applications approved.\nWe aim to use Poisson regression to analyze whether Blueprinty customers tend to receive more patents, after controlling for other factors.\n\n\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nblueprinty = pd.read_csv(\"blueprinty.csv\")\n\n# Histogram by customer status\nsns.histplot(data=blueprinty, x=\"patents\", hue=\"iscustomer\", multiple=\"dodge\", binwidth=1)\nplt.title(\"Number of Patents by Customer Status\")\nplt.xlabel(\"Number of Patents\")\nplt.ylabel(\"Count\")\nplt.show()\n\n# Age distribution\nsns.kdeplot(data=blueprinty, x=\"age\", hue=\"iscustomer\", fill=True, alpha=0.5)\nplt.title(\"Age Distribution by Customer Status\")\nplt.xlabel(\"Age\")\nplt.show()\n\n# Region counts\nprint(pd.crosstab(blueprinty[\"region\"], blueprinty[\"iscustomer\"]))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niscustomer    0    1\nregion              \nMidwest     187   37\nNortheast   273  328\nNorthwest   158   29\nSouth       156   35\nSouthwest   245   52\n\n\n\n\n\nBased on the plots and summary table, we observe several patterns: Patent Counts: Blueprinty customers tend to have slightly higher patent counts than non-customers. Both groups are right-skewed, but the customer group shows a longer tail, suggesting a few firms have notably more patents. Age Distribution: Customers are, on average, slightly older than non-customers. The age distribution for customers is flatter and shifted to the right, indicating broader age representation, while non-customers are more concentrated around their mid-to-late 20s.\nRegional Representation: The Northeast region has the largest number of customers (328), even more than non-customers (273), showing a strong customer base there. Regions like Midwest, Southwest, Northwest, and South have significantly more non-customers than customers. These patterns confirm that age and region are not balanced across groups and should be included as control variables in the Poisson regression.\n\n\n\n\nfrom scipy.stats import poisson\nfrom scipy.optimize import minimize\n\nY_obs = blueprinty[\"patents\"]\n\ndef poisson_loglikelihood(lam, Y):\n    return -np.sum(poisson.logpmf(Y, lam))\n\nlambdas = np.linspace(0.1, 10, 100)\nll_vals = [-poisson_loglikelihood(lam, Y_obs) for lam in lambdas]\n\nplt.plot(lambdas, ll_vals)\nplt.xlabel(\"lambda\")\nplt.ylabel(\"Log-Likelihood\")\nplt.title(\"Log-Likelihood for Poisson Model\")\nplt.show()\n\n# MLE estimate\nprint(\"Sample mean:\", Y_obs.mean())\n\nres = minimize(poisson_loglikelihood, x0=[1], args=(Y_obs,))\nprint(\"MLE lambda:\", res.x[0])\n\n\n\n\n\n\n\n\nSample mean: 3.6846666666666668\nMLE lambda: 3.684666637191825\n\n\nThe figure above displays the log-likelihood curve of a Poisson model using the observed number of patents across firms. We vary \\(\\lambda\\) across a range of values and compute the corresponding log-likelihood. The log-likelihood reaches its maximum at Œª = 3.6847, which matches the sample mean of the observed data. This result is expected: for a Poisson distribution, the maximum likelihood estimate (MLE) of Œª is equal to the sample mean. The curve shows a clear peak, verifying that the likelihood function is concave in this setting, and that our optimizer is finding the global maximum. This serves as a useful sanity check before moving on to the regression version of the model.\n\n\n\n\nimport patsy\nimport statsmodels.api as sm\n\nblueprinty[\"age2\"] = blueprinty[\"age\"] ** 2\ny, X = patsy.dmatrices(\"patents ~ age + age2 + C(region) + iscustomer\", data=blueprinty, return_type=\"dataframe\")\n\nmodel = sm.GLM(y, X, family=sm.families.Poisson())\nresults = model.fit()\nprint(results.summary())\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                patents   No. Observations:                 1500\nModel:                            GLM   Df Residuals:                     1492\nModel Family:                 Poisson   Df Model:                            7\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -3258.1\nDate:                Wed, 07 May 2025   Deviance:                       2143.3\nTime:                        19:50:19   Pearson chi2:                 2.07e+03\nNo. Iterations:                     5   Pseudo R-squ. (CS):             0.1360\nCovariance Type:            nonrobust                                         \n==========================================================================================\n                             coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------------------\nIntercept                 -0.5089      0.183     -2.778      0.005      -0.868      -0.150\nC(region)[T.Northeast]     0.0292      0.044      0.669      0.504      -0.056       0.115\nC(region)[T.Northwest]    -0.0176      0.054     -0.327      0.744      -0.123       0.088\nC(region)[T.South]         0.0566      0.053      1.074      0.283      -0.047       0.160\nC(region)[T.Southwest]     0.0506      0.047      1.072      0.284      -0.042       0.143\nage                        0.1486      0.014     10.716      0.000       0.121       0.176\nage2                      -0.0030      0.000    -11.513      0.000      -0.003      -0.002\niscustomer                 0.2076      0.031      6.719      0.000       0.147       0.268\n==========================================================================================\n\n\n\n\n\nThe Poisson regression output allows us to assess how different factors are associated with the number of patents a firm received over the past five years. Key insights include:\nIntercept: The baseline log-patent count for a firm in the omitted region (likely Midwest), with age = 0 and is not a customer, is approximately -0.51. This is not substantively interpretable but serves as a reference level.\nAge and Age¬≤:\nThe coefficient for age is positive and highly significant (0.1486, p &lt; 0.001), meaning older firms tend to have more patents.\nThe coefficient for age¬≤ is negative and highly significant (-0.003, p &lt; 0.001), indicating a concave relationship ‚Äî patent counts increase with age but at a decreasing rate.\nRegion:\nNone of the regional dummy variables are statistically significant (p &gt; 0.1), suggesting no strong evidence that patent counts differ systematically by region (after accounting for age and customer status).\nThe omitted base region is likely the one not listed (e.g., ‚ÄúMidwest‚Äù).\nCustomer Status:\nThe coefficient for iscustomer is positive (0.208) and highly significant (p &lt; 0.001), indicating that ‚Äî controlling for age and region ‚Äî Blueprinty customers tend to receive significantly more patents.\nInterpreting in real units: Since coefficients in Poisson models are in log-space, the effect size is: \\(\\exp(0.208) \\approx 1.23\\), meaning customers are expected to receive about 23% more patents than non-customers, all else equal.\nModel Fit:\nThe pseudo R¬≤ is 0.136, which is modest but acceptable in count data models.\nThe model converged in 5 iterations with a strong Pearson chi¬≤ statistic, indicating reasonable model fit.\n\n\n\n\nX0 = X.copy()\nX1 = X.copy()\nX0[\"iscustomer\"] = 0\nX1[\"iscustomer\"] = 1\n\ny_pred_0 = model.predict(results.params, exog=X0)\ny_pred_1 = model.predict(results.params, exog=X1)\n\nimpact = np.mean(y_pred_1 - y_pred_0)\nprint(\"Average increase in predicted patents for customers:\", round(impact, 2))\n\nAverage increase in predicted patents for customers: 0.79\n\n\nTo better interpret the coefficient on iscustomer, we simulate predicted outcomes using two hypothetical datasets:\nX0 is identical to the original covariate matrix but assumes none of the firms are Blueprinty customers (iscustomer = 0 for all).\nX1 is the same matrix but assumes all firms are customers (iscustomer = 1 for all).\nWe use the fitted Poisson regression model to predict the number of patents for each firm under both scenarios. Then, we compute the average difference:\nThe average predicted increase in patent count due to being a Blueprinty customer is 0.79.\nThis means that, holding firm age and region constant, Blueprinty software is associated with almost one additional patent per firm over 5 years, on average.\nThis result supports the company‚Äôs marketing claim that their software may improve patent success outcomes."
  },
  {
    "objectID": "blog/hw2/HW_2.html#blueprinty-case-study",
    "href": "blog/hw2/HW_2.html#blueprinty-case-study",
    "title": "Poisson Regression",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty‚Äôs software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty‚Äôs software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm‚Äôs number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty‚Äôs software. The marketing team would like to use this data to make the claim that firms using Blueprinty‚Äôs software are more successful in getting their patent applications approved.\nWe aim to use Poisson regression to analyze whether Blueprinty customers tend to receive more patents, after controlling for other factors.\n\n\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nblueprinty = pd.read_csv(\"blueprinty.csv\")\n\n# Histogram by customer status\nsns.histplot(data=blueprinty, x=\"patents\", hue=\"iscustomer\", multiple=\"dodge\", binwidth=1)\nplt.title(\"Number of Patents by Customer Status\")\nplt.xlabel(\"Number of Patents\")\nplt.ylabel(\"Count\")\nplt.show()\n\n# Age distribution\nsns.kdeplot(data=blueprinty, x=\"age\", hue=\"iscustomer\", fill=True, alpha=0.5)\nplt.title(\"Age Distribution by Customer Status\")\nplt.xlabel(\"Age\")\nplt.show()\n\n# Region counts\nprint(pd.crosstab(blueprinty[\"region\"], blueprinty[\"iscustomer\"]))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niscustomer    0    1\nregion              \nMidwest     187   37\nNortheast   273  328\nNorthwest   158   29\nSouth       156   35\nSouthwest   245   52\n\n\n\n\n\nBased on the plots and summary table, we observe several patterns: Patent Counts: Blueprinty customers tend to have slightly higher patent counts than non-customers. Both groups are right-skewed, but the customer group shows a longer tail, suggesting a few firms have notably more patents. Age Distribution: Customers are, on average, slightly older than non-customers. The age distribution for customers is flatter and shifted to the right, indicating broader age representation, while non-customers are more concentrated around their mid-to-late 20s.\nRegional Representation: The Northeast region has the largest number of customers (328), even more than non-customers (273), showing a strong customer base there. Regions like Midwest, Southwest, Northwest, and South have significantly more non-customers than customers. These patterns confirm that age and region are not balanced across groups and should be included as control variables in the Poisson regression.\n\n\n\n\nfrom scipy.stats import poisson\nfrom scipy.optimize import minimize\n\nY_obs = blueprinty[\"patents\"]\n\ndef poisson_loglikelihood(lam, Y):\n    return -np.sum(poisson.logpmf(Y, lam))\n\nlambdas = np.linspace(0.1, 10, 100)\nll_vals = [-poisson_loglikelihood(lam, Y_obs) for lam in lambdas]\n\nplt.plot(lambdas, ll_vals)\nplt.xlabel(\"lambda\")\nplt.ylabel(\"Log-Likelihood\")\nplt.title(\"Log-Likelihood for Poisson Model\")\nplt.show()\n\n# MLE estimate\nprint(\"Sample mean:\", Y_obs.mean())\n\nres = minimize(poisson_loglikelihood, x0=[1], args=(Y_obs,))\nprint(\"MLE lambda:\", res.x[0])\n\n\n\n\n\n\n\n\nSample mean: 3.6846666666666668\nMLE lambda: 3.684666637191825\n\n\nThe figure above displays the log-likelihood curve of a Poisson model using the observed number of patents across firms. We vary \\(\\lambda\\) across a range of values and compute the corresponding log-likelihood. The log-likelihood reaches its maximum at Œª = 3.6847, which matches the sample mean of the observed data. This result is expected: for a Poisson distribution, the maximum likelihood estimate (MLE) of Œª is equal to the sample mean. The curve shows a clear peak, verifying that the likelihood function is concave in this setting, and that our optimizer is finding the global maximum. This serves as a useful sanity check before moving on to the regression version of the model.\n\n\n\n\nimport patsy\nimport statsmodels.api as sm\n\nblueprinty[\"age2\"] = blueprinty[\"age\"] ** 2\ny, X = patsy.dmatrices(\"patents ~ age + age2 + C(region) + iscustomer\", data=blueprinty, return_type=\"dataframe\")\n\nmodel = sm.GLM(y, X, family=sm.families.Poisson())\nresults = model.fit()\nprint(results.summary())\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                patents   No. Observations:                 1500\nModel:                            GLM   Df Residuals:                     1492\nModel Family:                 Poisson   Df Model:                            7\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -3258.1\nDate:                Wed, 07 May 2025   Deviance:                       2143.3\nTime:                        19:50:19   Pearson chi2:                 2.07e+03\nNo. Iterations:                     5   Pseudo R-squ. (CS):             0.1360\nCovariance Type:            nonrobust                                         \n==========================================================================================\n                             coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------------------\nIntercept                 -0.5089      0.183     -2.778      0.005      -0.868      -0.150\nC(region)[T.Northeast]     0.0292      0.044      0.669      0.504      -0.056       0.115\nC(region)[T.Northwest]    -0.0176      0.054     -0.327      0.744      -0.123       0.088\nC(region)[T.South]         0.0566      0.053      1.074      0.283      -0.047       0.160\nC(region)[T.Southwest]     0.0506      0.047      1.072      0.284      -0.042       0.143\nage                        0.1486      0.014     10.716      0.000       0.121       0.176\nage2                      -0.0030      0.000    -11.513      0.000      -0.003      -0.002\niscustomer                 0.2076      0.031      6.719      0.000       0.147       0.268\n==========================================================================================\n\n\n\n\n\nThe Poisson regression output allows us to assess how different factors are associated with the number of patents a firm received over the past five years. Key insights include:\nIntercept: The baseline log-patent count for a firm in the omitted region (likely Midwest), with age = 0 and is not a customer, is approximately -0.51. This is not substantively interpretable but serves as a reference level.\nAge and Age¬≤:\nThe coefficient for age is positive and highly significant (0.1486, p &lt; 0.001), meaning older firms tend to have more patents.\nThe coefficient for age¬≤ is negative and highly significant (-0.003, p &lt; 0.001), indicating a concave relationship ‚Äî patent counts increase with age but at a decreasing rate.\nRegion:\nNone of the regional dummy variables are statistically significant (p &gt; 0.1), suggesting no strong evidence that patent counts differ systematically by region (after accounting for age and customer status).\nThe omitted base region is likely the one not listed (e.g., ‚ÄúMidwest‚Äù).\nCustomer Status:\nThe coefficient for iscustomer is positive (0.208) and highly significant (p &lt; 0.001), indicating that ‚Äî controlling for age and region ‚Äî Blueprinty customers tend to receive significantly more patents.\nInterpreting in real units: Since coefficients in Poisson models are in log-space, the effect size is: \\(\\exp(0.208) \\approx 1.23\\), meaning customers are expected to receive about 23% more patents than non-customers, all else equal.\nModel Fit:\nThe pseudo R¬≤ is 0.136, which is modest but acceptable in count data models.\nThe model converged in 5 iterations with a strong Pearson chi¬≤ statistic, indicating reasonable model fit.\n\n\n\n\nX0 = X.copy()\nX1 = X.copy()\nX0[\"iscustomer\"] = 0\nX1[\"iscustomer\"] = 1\n\ny_pred_0 = model.predict(results.params, exog=X0)\ny_pred_1 = model.predict(results.params, exog=X1)\n\nimpact = np.mean(y_pred_1 - y_pred_0)\nprint(\"Average increase in predicted patents for customers:\", round(impact, 2))\n\nAverage increase in predicted patents for customers: 0.79\n\n\nTo better interpret the coefficient on iscustomer, we simulate predicted outcomes using two hypothetical datasets:\nX0 is identical to the original covariate matrix but assumes none of the firms are Blueprinty customers (iscustomer = 0 for all).\nX1 is the same matrix but assumes all firms are customers (iscustomer = 1 for all).\nWe use the fitted Poisson regression model to predict the number of patents for each firm under both scenarios. Then, we compute the average difference:\nThe average predicted increase in patent count due to being a Blueprinty customer is 0.79.\nThis means that, holding firm age and region constant, Blueprinty software is associated with almost one additional patent per firm over 5 years, on average.\nThis result supports the company‚Äôs marketing claim that their software may improve patent success outcomes."
  },
  {
    "objectID": "blog/hw2/HW_2.html#airbnb-case-study",
    "href": "blog/hw2/HW_2.html#airbnb-case-study",
    "title": "Poisson Regression",
    "section": "Airbnb Case Study",
    "text": "Airbnb Case Study\n\nIntroduction\nAirbnb is a platform for booking short-term rentals. This dataset contains 40,000 listings in NYC scraped in 2017. We examine the number of reviews (as a proxy for bookings) as a function of host and listing characteristics.\n\n\nData\n\nairbnb = pd.read_csv(\"airbnb.csv\")\n\nairbnb_clean = airbnb[[\n    \"number_of_reviews\", \"days\", \"room_type\", \"bathrooms\", \"bedrooms\", \"price\",\n    \"review_scores_cleanliness\", \"review_scores_location\", \"review_scores_value\", \"instant_bookable\"\n]].dropna()\n\nairbnb_clean[\"instant_bookable\"] = airbnb_clean[\"instant_bookable\"].map({\"t\": 1, \"f\": 0})\n\ny_airbnb, X_airbnb = patsy.dmatrices(\"number_of_reviews ~ days + C(room_type) + bathrooms + bedrooms + price + review_scores_cleanliness + review_scores_location + review_scores_value + instant_bookable\",\n                                     data=airbnb_clean, return_type=\"dataframe\")\n# ÂèØËßÜÂåñ 1ÔºöÊàøÂûãÂàÜÂ∏É\nsns.countplot(data=airbnb_clean, x=\"room_type\")\nplt.title(\"Room Type Distribution\")\nplt.xlabel(\"Room Type\")\nplt.ylabel(\"Count\")\nplt.grid(axis='y')\nplt.tight_layout()\nplt.show()\n\n# ÂèØËßÜÂåñ 2Ôºö‰ª∑Ê†ºÂàÜÂ∏ÉÔºàÂéªÊéâÊûÅÁ´ØÈ´ò‰ª∑ÂêéÊõ¥Ê∏ÖÊô∞Ôºâ\nsns.histplot(data=airbnb_clean[airbnb_clean[\"price\"] &lt; 1000], x=\"price\", bins=50)\nplt.title(\"Price Distribution (&lt; $1000)\")\nplt.xlabel(\"Price\")\nplt.ylabel(\"Count\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n# ÂèØËßÜÂåñ 3ÔºöËØÑÂàÜ vs ËØÑ‰ª∑Êï∞Ôºà‰Ωú‰∏∫È¢ÑËÆ¢‰ª£ÁêÜÔºâ\nsns.scatterplot(data=airbnb_clean, x=\"review_scores_value\", y=\"number_of_reviews\", alpha=0.4)\nplt.title(\"Review Score (Value) vs. Number of Reviews\")\nplt.xlabel(\"Review Score: Value\")\nplt.ylabel(\"Number of Reviews\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBased on the plots above, we observe the following patterns:\nRoom Type Distribution: Entire homes/apartments are the most common room type, followed closely by private rooms. Shared rooms are rare. This suggests most listings are meant for exclusive use, possibly catering to tourists or families.\nPrice Distribution (&lt; $1000): Prices are right-skewed ‚Äî most listings fall between $50 and $300 per night, with a long tail extending beyond $1000. We limit the histogram to listings under $1000 to better visualize the distribution of typical prices.\nReview Score vs.¬†Review Count: Listings with higher value scores (mostly 9 or 10) tend to receive more reviews. This indicates a positive relationship between guest-perceived value and listing popularity (or booking frequency).\nThese insights help us understand the heterogeneity in listing types, pricing, and guest feedback ‚Äî all useful when constructing a predictive model for bookings.\n\n\nModeling Review Counts with Poisson Regression\n\nmodel_airbnb = sm.GLM(y_airbnb, X_airbnb, family=sm.families.Poisson())\nresults_airbnb = model_airbnb.fit()\nprint(results_airbnb.summary())\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:      number_of_reviews   No. Observations:                30160\nModel:                            GLM   Df Residuals:                    30149\nModel Family:                 Poisson   Df Model:                           10\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:            -5.2418e+05\nDate:                Wed, 07 May 2025   Deviance:                   9.2689e+05\nTime:                        19:50:20   Pearson chi2:                 1.37e+06\nNo. Iterations:                    10   Pseudo R-squ. (CS):             0.6840\nCovariance Type:            nonrobust                                         \n================================================================================================\n                                   coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------------------------\nIntercept                        3.4980      0.016    217.396      0.000       3.467       3.530\nC(room_type)[T.Private room]    -0.0105      0.003     -3.847      0.000      -0.016      -0.005\nC(room_type)[T.Shared room]     -0.2463      0.009    -28.578      0.000      -0.263      -0.229\ndays                          5.072e-05   3.91e-07    129.755      0.000       5e-05    5.15e-05\nbathrooms                       -0.1177      0.004    -31.394      0.000      -0.125      -0.110\nbedrooms                         0.0741      0.002     37.197      0.000       0.070       0.078\nprice                        -1.791e-05   8.33e-06     -2.151      0.031   -3.42e-05   -1.59e-06\nreview_scores_cleanliness        0.1131      0.001     75.611      0.000       0.110       0.116\nreview_scores_location          -0.0769      0.002    -47.796      0.000      -0.080      -0.074\nreview_scores_value             -0.0911      0.002    -50.490      0.000      -0.095      -0.088\ninstant_bookable                 0.3459      0.003    119.666      0.000       0.340       0.352\n================================================================================================\n\n\n\n\nInterpretation of Poisson Regression Results\nWe interpret the coefficients from the Poisson model as log-rate effects on the expected number of reviews, holding all other variables constant. Key insights include:\nRoom Type:\nCompared to the baseline (Entire home/apt), Private room has a small but significantly lower expected review count (coef = ‚Äì0.0105).\nShared room shows a larger negative effect (coef = ‚Äì0.2463), indicating these listings receive far fewer reviews.\nDays on Platform: The coefficient for days is positive and highly significant. Each additional day the listing is active increases the log-expected review count slightly, consistent with older listings accumulating more reviews.\nBathrooms: Negative coefficient (‚Äì0.1177) suggests listings with more bathrooms get fewer reviews, possibly due to being larger and more expensive ‚Äî or reflecting multibathroom listings in less popular areas.\nBedrooms: Positive and significant. Listings with more bedrooms receive more reviews, indicating higher occupancy capacity is attractive to renters.\nPrice: A higher price slightly decreases the expected review count. Though the effect is small (‚Äì1.79e‚Äì5), it‚Äôs statistically significant, aligning with intuition that higher prices may reduce booking frequency.\nReview Scores:\nCleanliness has a strong positive association with reviews ‚Äî cleaner listings tend to get booked and reviewed more.\nLocation and Value scores are negatively associated with review count, which may seem counterintuitive. One possible reason is that extremely popular listings (with many reviews) may face greater scrutiny, leading to slightly harsher location/value ratings.\nInstant Bookable: The largest positive effect (coef = 0.3459). Listings with instant booking enabled receive far more reviews on average, likely because they remove friction for renters and appear more convenient in search results."
  },
  {
    "objectID": "blog/hw2/HW_2.html#conclusion",
    "href": "blog/hw2/HW_2.html#conclusion",
    "title": "Poisson Regression",
    "section": "Conclusion",
    "text": "Conclusion\nThis project demonstrates how Poisson regression can be used to model count data‚Äîin this case, the number of patent awards or Airbnb reviews‚Äîas a function of meaningful covariates.\nIn the Blueprinty case, we find that firms using Blueprinty‚Äôs software are predicted to receive approximately 0.79 more patents on average than comparable non-customers, holding age and region constant. This provides modest evidence in support of the software‚Äôs effectiveness.\nIn the Airbnb case, we use the number of reviews as a proxy for bookings. Our Poisson regression model reveals that:\nListings with instant booking enabled receive significantly more reviews.\nLower prices, higher cleanliness ratings, and more bedrooms are associated with increased review counts.\nShared rooms tend to have far fewer reviews compared to full homes.\nTogether, these results show that Poisson regression provides a useful and interpretable framework for understanding count-based outcomes in both industrial and consumer-facing domains."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Your browser does not support PDFs. &lt;a href=\"resume/Resume.pdf\"&gt;Download the PDF&lt;/a&gt;."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Zewei Chen",
    "section": "",
    "text": "Hi! I‚Äôm Zewei Chen ‚Äî welcome to my personal website.\nCurrently pursuing MSBA at UCSD\nPassionate about data science, analytics, and technology\nAlways exploring how data can tell meaningful stories"
  },
  {
    "objectID": "blog/project1/index.html",
    "href": "blog/project1/index.html",
    "title": "Creative Gaming: Propensity-to-Buy Modeling",
    "section": "",
    "text": "This project builds a predictive model for Creative Gaming‚Äôs mobile title Space Pirates. The business goal is to identify players most likely to buy the premium Zalon campaign and evaluate how in-app ads and modeling strategies influence campaign performance.\nWe use telemetry data for over 200,000 users and analyze conversion rates, profits, and model performance across multiple targeting strategies."
  },
  {
    "objectID": "blog/project1/index.html#project-overview",
    "href": "blog/project1/index.html#project-overview",
    "title": "Creative Gaming: Propensity-to-Buy Modeling",
    "section": "",
    "text": "This project builds a predictive model for Creative Gaming‚Äôs mobile title Space Pirates. The business goal is to identify players most likely to buy the premium Zalon campaign and evaluate how in-app ads and modeling strategies influence campaign performance.\nWe use telemetry data for over 200,000 users and analyze conversion rates, profits, and model performance across multiple targeting strategies."
  },
  {
    "objectID": "blog/project1/index.html#data-setup",
    "href": "blog/project1/index.html#data-setup",
    "title": "Creative Gaming: Propensity-to-Buy Modeling",
    "section": "üìÅ Data & Setup",
    "text": "üìÅ Data & Setup\n\ncg_organic.parquet: 30K players, organically converted or not\ncg_organic_control.parquet: 30K users, control group for ad experiment\ncg_ad_treatment.parquet: 150K users exposed to ads, tagged for random/model targeting\nFeatures include behavior (sessions, badges, roles), purchase history, and device info"
  },
  {
    "objectID": "blog/project1/index.html#part-i-exploratory-data-analysis-eda",
    "href": "blog/project1/index.html#part-i-exploratory-data-analysis-eda",
    "title": "Creative Gaming: Propensity-to-Buy Modeling",
    "section": "üîç Part I: Exploratory Data Analysis (EDA)",
    "text": "üîç Part I: Exploratory Data Analysis (EDA)\n\nOrganic conversion rate: 5.75%\nHistogram & frequency plots created for all features\nKey variables include:\n\nNumGameDays, NumSpaceHeroBadges, NumAdsClicked, GameLevel, PurchasedCoinPackLarge\n\nNo missing data; variable ranges and distributions look appropriate for modeling"
  },
  {
    "objectID": "blog/project1/index.html#part-ii-logistic-regression-modeling",
    "href": "blog/project1/index.html#part-ii-logistic-regression-modeling",
    "title": "Creative Gaming: Propensity-to-Buy Modeling",
    "section": "ü§ñ Part II: Logistic Regression Modeling",
    "text": "ü§ñ Part II: Logistic Regression Modeling\nWe trained a logistic regression model using the training set (training == 1). Model performance:\n\nTop 5 Features:\n\nNumSpaceHeroBadges (+)\nNumFriendRequestIgnored (-)\nTimesLostSpaceship (-)\nGameLevel (+)\nNumAdsClicked (+)\n\nAUC:\n\nTrain: 0.820\nTest: 0.803\n\n\n\nInterpretation: In-game engagement (badges, ad clicks) positively correlates with purchase behavior; social avoidance or in-game failure reduces likelihood."
  },
  {
    "objectID": "blog/project1/index.html#part-iii-evaluating-the-ad-experiment",
    "href": "blog/project1/index.html#part-iii-evaluating-the-ad-experiment",
    "title": "Creative Gaming: Propensity-to-Buy Modeling",
    "section": "üìà Part III: Evaluating the Ad Experiment",
    "text": "üìà Part III: Evaluating the Ad Experiment\n\nüéØ Experiment Groups (Each with 30,000 users)\n\n\n\n\n\n\n\n\n\nGroup\nDescription\nConversion Rate\nProfit\n\n\n\n\nG1\nNo ads (control)\n5.69%\n$25,572.94\n\n\nG2\nRandom ad exposure\n13.04%\n$13,655.87\n\n\nG3\nModel-selected ad targeting\n21.51%\n$51,715.48\n\n\n\n\nAd lift (G2 vs G1): +129%\nModel lift (G3 vs G2): +65%\nROI from model-based targeting: +279%"
  },
  {
    "objectID": "blog/project1/index.html#part-iv-retraining-on-ad-response",
    "href": "blog/project1/index.html#part-iv-retraining-on-ad-response",
    "title": "Creative Gaming: Propensity-to-Buy Modeling",
    "section": "üîÅ Part IV: Retraining on Ad Response",
    "text": "üîÅ Part IV: Retraining on Ad Response\nRetrained logistic regression using ad-exposed users (G2). Compared predictions on G3 population:\n\nAUC of ‚Äúorganic‚Äù model: 0.644\nAUC of new ‚Äúad‚Äù model: 0.703\n\n\nRetraining on ad data improved accuracy in identifying ad-sensitive users."
  },
  {
    "objectID": "blog/project1/index.html#part-v-machine-learning-comparison",
    "href": "blog/project1/index.html#part-v-machine-learning-comparison",
    "title": "Creative Gaming: Propensity-to-Buy Modeling",
    "section": "üß† Part V: Machine Learning Comparison",
    "text": "üß† Part V: Machine Learning Comparison\n\n\n\nModel\nAUC\nConversion Rate\nProfit\n\n\n\n\nLogistic (ad)\n0.703\n27.39%\n$78,172.83\n\n\nNeural Network\n0.780\n30.99%\n$94,377.02\n\n\nRandom Forest\n0.779\n31.15%\n$95,096.54\n\n\n\n\nBoth ML models outperformed logistic regression. Neural network showed the highest AUC; random forest yielded the highest profit."
  },
  {
    "objectID": "blog/project1/index.html#conclusion",
    "href": "blog/project1/index.html#conclusion",
    "title": "Creative Gaming: Propensity-to-Buy Modeling",
    "section": "üßæ Conclusion",
    "text": "üßæ Conclusion\nAds significantly improve conversion and revenue for the Zalon campaign, and targeted ad selection via machine learning yields the highest ROI. Combining experimentation with modeling is key to unlocking profitable, data-driven decisions in mobile gaming."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I‚Äôm a Master of Science in Business Analytics (MSBA) student at the Rady School of Management, UC San Diego. With hands-on experience in data analytics, financial services, and marketing strategy, I‚Äôm passionate about using data to solve real-world problems and tell meaningful stories."
  },
  {
    "objectID": "about.html#hi-im-zewei-chen",
    "href": "about.html#hi-im-zewei-chen",
    "title": "About",
    "section": "",
    "text": "I‚Äôm a Master of Science in Business Analytics (MSBA) student at the Rady School of Management, UC San Diego. With hands-on experience in data analytics, financial services, and marketing strategy, I‚Äôm passionate about using data to solve real-world problems and tell meaningful stories."
  },
  {
    "objectID": "about.html#education-skills",
    "href": "about.html#education-skills",
    "title": "About",
    "section": "üéì Education & Skills",
    "text": "üéì Education & Skills\n\nGPA: 3.46 / 4.0\n\nCore Courses: SQL & ETL, Customer Analytics and AI, Fraud Analytics, Business Analytics\n\nTech Stack: Python, SQL, Power BI, R, ETL tools\n\nLanguages: English (fluent), Mandarin Chinese (native)"
  },
  {
    "objectID": "about.html#personal-interests",
    "href": "about.html#personal-interests",
    "title": "About",
    "section": "üèÄ Personal Interests",
    "text": "üèÄ Personal Interests\nOutside of academics and data science, I love playing basketball üèÄ. It keeps me energized, focused, and reminds me of the value of teamwork ‚Äî both on the court and in data projects."
  },
  {
    "objectID": "about.html#professional-experience-highlights",
    "href": "about.html#professional-experience-highlights",
    "title": "About",
    "section": "üíº Professional Experience Highlights",
    "text": "üíº Professional Experience Highlights\n\nIntuit Inc.: Built predictive models for direct mail campaign optimization.\n\nChina Securities: Conducted macroeconomic research and financial modeling.\n\nICBC: Supported cross-border financial operations and reporting.\n\n\nFeel free to explore my resume or connect with me on LinkedIn."
  }
]